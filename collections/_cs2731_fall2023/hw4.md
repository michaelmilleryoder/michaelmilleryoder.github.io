---
layout: class
title: Homework 4 (CS 2731 Fall 2023)
---

# Homework 4: Sequence labeling ([CS 2731 Fall 2023](https://michaelmilleryoder.github.io/cs2731_fall2023/))
**Due 2023-11-09, 11:59pm**. *Instructions last updated 2023-10-30.*

In this assignment, you will manually decode the highest-probability sequence of part-of-speech tags from a trained HMM using the Viterbi algorithm. You will also fine-tune a BERT-based model for named entity recognition (NER).

<!--
The learning goals of this assignment are to:

* Understand how to compute language model probabilities using maximum likelihood estimation.
* Implement basic smoothing and interpolation.
* Use the perplexity of a language model to perform language identification.
* Use a language model to probabilistically generate texts.
-->


# 1. POS tagging with an HMM
Consider a Hidden Markov Model with the following parameters:
postags = {NOUN, AUX, VERB}, words = {'Patrick', 'Cherry', 'can', 'will', 'see', 'spot'}

Initial probabilities:

&nbsp; | $$\pi$$
--|--------
NOUN|0.7
AUX|0.1
VERB|0.2

Transition probabilities: 
The format is P(column\_tag \| row\_tag), e.g. $$P(AUX \vert NOUN) = 0.3$$

 &nbsp;| NOUN | AUX | VERB
--|---|---|--
NOUN|0.2|0.3|0.5
AUX|0.4|0.1|0.5
VERB|0.8|0.1|0.1

Emission probabilities:

 &nbsp;| Patrick | Cherry | can | will | see | spot
--|---|---|--|--|--|--
NOUN|0.3|0.2|0.1|0.1|0.1|0.2
AUX|0|0|0.4|0.6|0|0
VERB|0|0|0.1|0.2|0.5|0.2

## Deliverables for part 1
Using the Viterbi algorithm and the given HMM, find the most likely tag sequence for the following 2 sentences. Show your work and the most likely tag sequences in your report.
1. “Patrick can see Cherry”
1. “will Cherry spot Patrick”

# 2. Fine-tune a BERT-based NER model

## Deliverables for part 2
In your report, include:
4. for the linear interpolated model (and optional add-one model), the average perplexity score across all lines in the test document, as well as which language each model estimates the test document is written in (has the lowest perplexity).
5. generated text outputs for the following inputs: bigrams starting with 10 letters of your choice, and trigrams using those 10 letters as the first character with a second meaningful character of your choice. 
6. critical analysis of your language identification results: e.g., why do your perplexity scores tell you what language the test data is written in? what does a comparison of your unigram, bigram, and trigram scores tell you about which performs best? etc.
7. critical analysis of your generation results: e.g., are there any difference between the sentences generated by bigrams and trigrams, or by the unsmoothed versus smoothed models? Give examples to back up your conclusions.


## Submission
Please submit the following items on Canvas:

* Your report with results and answers to questions in Part 1 and Part 2, named `report_{your pitt email id}_hw3.pdf`. No need to include @pitt.edu, just use the email ID before that part. For example: `report_mmy29_hw3.pdf`.
* The code of your program
* Model files (ngram probabilities) ideally in a human-readable format (CSV, JSON, etc)
* A `README.txt` file explaining
	* how to run your code
	* the computing environment you used; what programming language you used and the major and minor version of that language; what packages did you use in case we replicate your experiments (a `requirements.txt` file for setting up the environment may be useful if there are many packages).
	* any additional resources, references, or web pages you've consulted
	* any person with whom you've discussed the assignment and describe the nature of your discussions
	* any generative AI tool used, and how it was used
	* any unresolved issues or problems

This homework assignment is worth 45 points.


## Acknowledgments
This assignment is based on homework assignments by Prof. Hyeju Jang and Prof. Diane Litman.

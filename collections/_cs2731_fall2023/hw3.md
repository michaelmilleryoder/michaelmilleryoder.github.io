---
layout: class
title: Homework 3 (CS 2731 Fall 2023)
---

# Homework 3: Language modeling ([CS 2731 Fall 2023](https://michaelmilleryoder.github.io/cs2731_fall2023/))
**Due 2023-11-02, 11:59pm**. *Instructions last updated 2023-10-20.*

In this assignment, you will build unigram, bigram, and trigram character language models (both unsmoothed and smoothed versions) for three languages, score a test document with each, and determine the language it is written in based on perplexity. You will also use your English language models to generate texts. You will critically examine all results. The learning goals of this assignment are to:

* Understand how to compute language model probabilities using maximum likelihood estimation.
* Implement basic smoothing and interpolation.
* Use the perplexity of a language model to perform language identification.
* Use a language model to probabilistically generate texts.

# Data
The data for this project is available here:`[hw3_data.zip](hw3/hw3_data.zip)` . It consists of:

    * training.en - English training data
    * training.es - Spanish training data
    * training.de - German training data
    * test - test document


# 1. Train n-gram language models
To complete the assignment, you will need to write a program (from scratch) that:

    * builds the models: reads in training data, collects counts for all **character** 1, 2, and 3-grams, estimates probabilities, and writes out the unigram, bigram, and trigram models into files
    * adjusts the counts: rebuilds the bigram and trigram language models using two different methods: add-one smoothing and linear interpolation with lambdas equally weighted

You may make any additional assumptions and design decisions, but state them in your report (see below). For example, some design choices that could be made are how you want to handle uppercase and lowercase letters or how you want to handle digits. The choice made is up to you, we only require that you detail these decisions in your report and consider any implications of them in your results. There is no wrong choice here, and these decisions are typically made by NLP researchers when pre-processing data.

You may write your program in any TA-approved programming language (Python, Java, C/C++).

For this assignment you must implement the model generation from scratch, but you are allowed to use any resources or packages that help you manage your project, i.e. Github or any file i/o packages. If you have questions about this please ask. 

## Deliverables for part 1
In your report, include:
1. a description of how you wrote your program, including all assumptions and design decisions
2. an excerpt of the two untuned trigram language models for English, displaying all n-grams and their probability with the two-character history t h
3. documentation that your probability distributions are valid (sum to 1) 
4. for all your unsmoothed and smoothed models, the average perplexity score across all lines in the test document.
5. generated text outputs for the following inputs: bigrams starting with 10 letters of your choice, and trigrams using those 10 letters as the first character with a second meaningful character of your choice. 

# 2. Use n-gram language models
* Language identification: For all trained language models, read in the test document, apply the language model to all sentences in it, and output perplexity. Based on the results, identify the language of the test document.
* Text generation: For only the bigram and trigram language models trained on English, extend your programs so that you can generate sentences. That is, given any English letter(s) as input and based on the n-gram model you should continue the sentence with the most likely characters. More specifically, given a letter to begin a sentence with, you should choose as the next character that character that yields the highest n-gram count when composed with previous characters into a n-gram. Thus, you will use the previous character for bigrams and previous two characters for trigrams. You should continue generating new characters until you have generated a 100 character sentence or you have reached a dead end (all n-gram counts are zero).  

## Deliverables for part 2
In your report, include:
6. critical analysis of your language identification results: e.g., why do your perplexity scores tell you what language the test data is written in? what does a comparison of your unsmoothed versus smoothed scores tell you about which performs best? what does a comparison of your unigram, bigram, and trigram scores tell you about which performs best? etc.
7. critical analysis of your generation results: e.g., are there any difference between the sentences generated by bigrams and trigrams, or by the unsmoothed versus smoothed models? Give examples to back up your conclusions.


## Submission
Please submit the following items on Canvas:

* Your report with results and answers to questions in Part 1 and Part 2, named `report_{your pitt email id}_hw3.pdf`. No need to include @pitt.edu, just use the email ID before that part. For example: `report_mmy29_hw3.pdf`.
* The code of your program
* A `README.txt` file explaining
	* how to run your code
	* the computing environment you used; what programming language you used and the major and minor version of that language; what packages did you use in case we replicate your experiments (a `requirements.txt` file for setting up the environment may be useful if there are many packages).
	* any additional resources, references, or web pages you've consulted
	* any person with whom you've discussed the assignment and describe the nature of your discussions
	* any generative AI tool used, and how it was used
	* any unresolved issues or problems


## Acknowledgments
This assignment is based on a homework assignment by Prof. Diane Litman.
